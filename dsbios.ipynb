{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN06FJIvIhipm2jxPfjE20I"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWf2TDYfd7PE"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Colab basics\n",
        "print(\"Python:\", sys.version)\n",
        "\n",
        "# Keep installs small-ish. If you already ran this once, you can skip it.\n",
        "!pip -q install pandas numpy pyarrow lightgbm scikit-learn requests\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "# Project folder so the Files pane doesn't turn into a mess\n",
        "WORK = Path(\"/content/dsbios\")\n",
        "WORK.mkdir(exist_ok=True)\n",
        "os.chdir(WORK)\n",
        "\n",
        "print(\"Working dir:\", WORK)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "FILE = Path(\"drugshortages.json\")\n",
        "if not FILE.exists():\n",
        "    raise FileNotFoundError(\n",
        "        \"Missing drugshortages.json. Upload your OpenFDA download and rename it to 'drugshortages.json'.\"\n",
        "    )\n",
        "\n",
        "print(\"Found drugshortages.json (MB):\", round(FILE.stat().st_size / 1e6, 2))\n",
        "\n",
        "# Load JSON and figure out where the actual records live\n",
        "with open(FILE, \"r\") as f:\n",
        "    raw = json.load(f)\n",
        "\n",
        "if isinstance(raw, dict):\n",
        "    if \"results\" in raw:\n",
        "        records = raw[\"results\"]\n",
        "    elif \"data\" in raw:\n",
        "        records = raw[\"data\"]\n",
        "    else:\n",
        "        raise RuntimeError(f\"Don't recognize JSON keys: {list(raw.keys())[:30]}\")\n",
        "elif isinstance(raw, list):\n",
        "    records = raw\n",
        "else:\n",
        "    raise RuntimeError(f\"Unexpected JSON root type: {type(raw)}\")\n",
        "\n",
        "print(\"Records:\", len(records))\n",
        "\n",
        "# Pull only what we need\n",
        "rows = []\n",
        "for r in records:\n",
        "    tc = r.get(\"therapeutic_category\", \"\")\n",
        "    if isinstance(tc, list):\n",
        "        tc = \", \".join(tc)\n",
        "\n",
        "    rows.append({\n",
        "        \"generic_name\": r.get(\"generic_name\", \"\"),\n",
        "        \"initial_posting_date\": r.get(\"initial_posting_date\", \"\"),\n",
        "        \"status\": r.get(\"status\", \"\"),\n",
        "        \"dosage_form\": r.get(\"dosage_form\", \"\"),\n",
        "        \"therapeutic_category\": tc,\n",
        "        \"company_name\": r.get(\"company_name\", \"\")\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(\"Raw shape:\", df.shape)\n",
        "\n",
        "def normalize_drug(name: str) -> str:\n",
        "    if not isinstance(name, str):\n",
        "        return \"\"\n",
        "    s = name.lower()\n",
        "    s = re.sub(r\"\\(.*?\\)\", \"\", s)                 # strip parentheses junk\n",
        "    s = re.sub(r\"[^a-z0-9\\s\\-\\/]\", \" \", s)        # keep basic tokens\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "df[\"drug_norm\"] = df[\"generic_name\"].apply(normalize_drug)\n",
        "\n",
        "# Dates\n",
        "df[\"start_date\"] = pd.to_datetime(df[\"initial_posting_date\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"start_date\"]).copy()\n",
        "df[\"start_year\"] = df[\"start_date\"].dt.year.astype(int)\n",
        "\n",
        "# Count shortage starts per (drug, year)\n",
        "shortage_events = (\n",
        "    df.groupby([\"drug_norm\", \"start_year\"])\n",
        "      .size()\n",
        "      .reset_index(name=\"shortages_started\")\n",
        ")\n",
        "\n",
        "shortage_events.to_csv(\"shortage_events_by_drug_year.csv\", index=False)\n",
        "print(\"Saved shortage_events_by_drug_year.csv (rows):\", len(shortage_events))\n"
      ],
      "metadata": {
        "id": "rKqL7tS5d9Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "REQUIRED = [\n",
        "    \"shortage_events_by_drug_year.csv\",\n",
        "    \"orange_book.zip\",\n",
        "    \"partd_spending_by_drug.csv\"\n",
        "]\n",
        "\n",
        "missing = []\n",
        "for f in REQUIRED:\n",
        "    p = Path(f)\n",
        "    if not p.exists():\n",
        "        missing.append(f)\n",
        "\n",
        "if missing:\n",
        "    raise RuntimeError(\n",
        "        \"Missing files:\\n  - \" + \"\\n  - \".join(missing) +\n",
        "        \"\\n\\nUpload them with the exact names and rerun.\"\n",
        "    )\n",
        "\n",
        "print(\"All required inputs present.\")\n"
      ],
      "metadata": {
        "id": "a4hAuHIfd9_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "ORANGE_ZIP = Path(\"orange_book.zip\")\n",
        "if not ORANGE_ZIP.exists():\n",
        "    raise FileNotFoundError(\"orange_book.zip not found.\")\n",
        "\n",
        "out_dir = Path(\"orange_book_unzipped\")\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(ORANGE_ZIP, \"r\") as z:\n",
        "    z.extractall(out_dir)\n",
        "\n",
        "# Find Products*.txt (Orange Book naming varies a bit)\n",
        "products_candidates = [p for p in out_dir.glob(\"*\") if p.name.lower().startswith(\"products\")]\n",
        "if not products_candidates:\n",
        "    raise RuntimeError(\"Couldn't find a Products file after unzip. Check what's inside the zip.\")\n",
        "\n",
        "PRODUCTS_TXT = products_candidates[0]\n",
        "print(\"Using Products file:\", PRODUCTS_TXT.name)\n"
      ],
      "metadata": {
        "id": "WhsJ9Ne-d_qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "out_dir = Path(\"orange_book_unzipped\")\n",
        "products_candidates = [p for p in out_dir.glob(\"*\") if p.name.lower().startswith(\"products\")]\n",
        "if not products_candidates:\n",
        "    raise RuntimeError(\"Products file not found. Rerun the unzip cell.\")\n",
        "PRODUCTS_TXT = products_candidates[0]\n",
        "\n",
        "# Orange Book Products is usually \"~\" delimited\n",
        "products = pd.read_csv(PRODUCTS_TXT, sep=\"~\", dtype=str, engine=\"python\")\n",
        "\n",
        "def find_col(df, keywords):\n",
        "    for k in keywords:\n",
        "        for c in df.columns:\n",
        "            if k in c.lower():\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "ingredient_col = find_col(products, [\"ingredient\"])\n",
        "applicant_col  = find_col(products, [\"applicant\"])\n",
        "\n",
        "if ingredient_col is None or applicant_col is None:\n",
        "    raise RuntimeError(\n",
        "        \"Couldn't auto-find ingredient/applicant columns.\\n\"\n",
        "        f\"Columns: {list(products.columns)}\"\n",
        "    )\n",
        "\n",
        "def normalize_drug(name: str) -> str:\n",
        "    if not isinstance(name, str):\n",
        "        return \"\"\n",
        "    s = name.lower()\n",
        "    s = re.sub(r\"\\(.*?\\)\", \"\", s)\n",
        "    s = re.sub(r\"[^a-z0-9\\s\\-\\/]\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "ob = products[[ingredient_col, applicant_col]].copy()\n",
        "ob.columns = [\"ingredient\", \"applicant\"]\n",
        "\n",
        "ob[\"drug_norm\"] = ob[\"ingredient\"].apply(normalize_drug)\n",
        "ob[\"applicant_norm\"] = ob[\"applicant\"].fillna(\"\").astype(str).str.lower().str.strip()\n",
        "\n",
        "manufacturer_counts = (\n",
        "    ob.groupby(\"drug_norm\")[\"applicant_norm\"]\n",
        "      .nunique()\n",
        "      .reset_index(name=\"num_manufacturers\")\n",
        ")\n",
        "\n",
        "manufacturer_counts[\"num_manufacturers\"] = manufacturer_counts[\"num_manufacturers\"].fillna(0).astype(int)\n",
        "manufacturer_counts.to_csv(\"manufacturer_counts_by_drug.csv\", index=False)\n",
        "\n",
        "print(\"Saved manufacturer_counts_by_drug.csv (rows):\", len(manufacturer_counts))\n"
      ],
      "metadata": {
        "id": "xpc4aAIveAVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "PARTD = Path(\"partd_spending_by_drug.csv\")\n",
        "if not PARTD.exists():\n",
        "    raise FileNotFoundError(\"partd_spending_by_drug.csv not found.\")\n",
        "\n",
        "cols = pd.read_csv(PARTD, nrows=0).columns.tolist()\n",
        "print(\"Columns:\", cols)\n",
        "print(\"\\nSample:\")\n",
        "print(pd.read_csv(PARTD, nrows=5, dtype=str))\n"
      ],
      "metadata": {
        "id": "h-mB5whieCQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "PARTD = Path(\"partd_spending_by_drug.csv\")\n",
        "df = pd.read_csv(PARTD, dtype=str)\n",
        "\n",
        "needed = [\"Gnrc_Name\", \"Mftr_Name\"]\n",
        "for c in needed:\n",
        "    if c not in df.columns:\n",
        "        raise RuntimeError(f\"Missing '{c}'. Found columns: {list(df.columns)}\")\n",
        "\n",
        "claim_cols = [c for c in df.columns if c.startswith(\"Tot_Clms_\")]\n",
        "if not claim_cols:\n",
        "    raise RuntimeError(\"No Tot_Clms_YYYY columns found. Check the file format.\")\n",
        "\n",
        "# Avoid double counting: keep only the \"Overall\" row per drug\n",
        "overall_mask = df[\"Mftr_Name\"].astype(str).str.strip().str.lower() == \"overall\"\n",
        "df_overall = df[overall_mask].copy()\n",
        "if df_overall.empty:\n",
        "    raise RuntimeError(\"Couldn't find rows where Mftr_Name == 'Overall'. Check Mftr_Name values.\")\n",
        "\n",
        "def normalize_drug(name: str) -> str:\n",
        "    if not isinstance(name, str):\n",
        "        return \"\"\n",
        "    s = name.lower()\n",
        "    s = re.sub(r\"\\(.*?\\)\", \"\", s)\n",
        "    s = re.sub(r\"[^a-z0-9\\s\\-\\/]\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "df_overall[\"drug_norm\"] = df_overall[\"Gnrc_Name\"].fillna(\"\").astype(str).apply(normalize_drug)\n",
        "\n",
        "rows = []\n",
        "for col in claim_cols:\n",
        "    # expecting Tot_Clms_2019, etc.\n",
        "    try:\n",
        "        year = int(col.split(\"_\")[-1])\n",
        "    except ValueError:\n",
        "        continue\n",
        "\n",
        "    tmp = df_overall[[\"drug_norm\", col]].copy()\n",
        "    tmp = tmp.rename(columns={col: \"claims\"})\n",
        "    tmp[\"claims\"] = pd.to_numeric(tmp[\"claims\"].astype(str).str.replace(\",\", \"\"), errors=\"coerce\").fillna(0)\n",
        "    tmp[\"year\"] = year\n",
        "    rows.append(tmp)\n",
        "\n",
        "demand = pd.concat(rows, ignore_index=True)\n",
        "demand = demand.groupby([\"drug_norm\", \"year\"], as_index=False)[\"claims\"].sum()\n",
        "\n",
        "demand.to_csv(\"demand_by_drug_year.csv\", index=False)\n",
        "print(\"Saved demand_by_drug_year.csv (rows):\", len(demand), \"| years:\", sorted(demand[\"year\"].unique()))\n"
      ],
      "metadata": {
        "id": "f70sCHoAeD3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "FORM_WORDS = set(\"\"\"\n",
        "tablet tablets tab capsule capsules cap solution solutions soln injection injections inj\n",
        "suspension suspensions susp syrup ointment cream gel spray patch patches aerosol foam\n",
        "extended release er xr dr sr delayed release immediate release\n",
        "iv intravenous im intramuscular subcutaneous sc oral rectal topical ophthalmic otic nasal\n",
        "\"\"\".split())\n",
        "\n",
        "def drug_key(name: str) -> str:\n",
        "    if not isinstance(name, str):\n",
        "        return \"\"\n",
        "    s = name.lower()\n",
        "    s = re.sub(r\"\\(.*?\\)\", \" \", s)\n",
        "    s = s.replace(\"%\", \" \")\n",
        "    s = re.sub(r\"[^a-z0-9\\s\\-\\/]\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "    toks = []\n",
        "    for t in s.split():\n",
        "        if t.isdigit():\n",
        "            continue\n",
        "        if re.fullmatch(r\"\\d+(\\.\\d+)?\", t):\n",
        "            continue\n",
        "        if t in FORM_WORDS:\n",
        "            continue\n",
        "        toks.append(t)\n",
        "\n",
        "    return \" \".join(sorted(set(toks)))\n",
        "\n",
        "# Add drug_key into all three datasets (in-place)\n",
        "demand = pd.read_csv(\"demand_by_drug_year.csv\")\n",
        "mfg    = pd.read_csv(\"manufacturer_counts_by_drug.csv\")\n",
        "labels = pd.read_csv(\"shortage_events_by_drug_year.csv\")\n",
        "\n",
        "for name, df in [(\"demand\", demand), (\"mfg\", mfg), (\"labels\", labels)]:\n",
        "    if \"drug_norm\" not in df.columns:\n",
        "        raise RuntimeError(f\"{name} is missing drug_norm. Columns: {list(df.columns)}\")\n",
        "\n",
        "demand[\"drug_key\"] = demand[\"drug_norm\"].apply(drug_key)\n",
        "mfg[\"drug_key\"]    = mfg[\"drug_norm\"].apply(drug_key)\n",
        "labels[\"drug_key\"] = labels[\"drug_norm\"].apply(drug_key)\n",
        "\n",
        "demand.to_csv(\"demand_by_drug_year.csv\", index=False)\n",
        "mfg.to_csv(\"manufacturer_counts_by_drug.csv\", index=False)\n",
        "labels.to_csv(\"shortage_events_by_drug_year.csv\", index=False)\n",
        "\n",
        "print(\"Added drug_key to demand/mfg/labels and saved.\")\n"
      ],
      "metadata": {
        "id": "Ee6wV5NReFCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "demand = pd.read_csv(\"demand_by_drug_year.csv\")\n",
        "mfg    = pd.read_csv(\"manufacturer_counts_by_drug.csv\")\n",
        "labels = pd.read_csv(\"shortage_events_by_drug_year.csv\")\n",
        "\n",
        "# labels might have start_year depending on where it came from\n",
        "labels2 = labels.copy()\n",
        "if \"year\" in labels2.columns:\n",
        "    labels2[\"year\"] = pd.to_numeric(labels2[\"year\"], errors=\"coerce\")\n",
        "elif \"start_year\" in labels2.columns:\n",
        "    labels2 = labels2.rename(columns={\"start_year\": \"year\"})\n",
        "    labels2[\"year\"] = pd.to_numeric(labels2[\"year\"], errors=\"coerce\")\n",
        "else:\n",
        "    raise RuntimeError(f\"Labels file missing year/start_year. Columns: {list(labels2.columns)}\")\n",
        "\n",
        "labels2 = labels2.dropna(subset=[\"year\"]).copy()\n",
        "labels2[\"year\"] = labels2[\"year\"].astype(int)\n",
        "\n",
        "if \"shortages_started\" not in labels2.columns:\n",
        "    raise RuntimeError(f\"Labels file missing shortages_started. Columns: {list(labels2.columns)}\")\n",
        "\n",
        "# Set of (drug_key, year) where a shortage starts\n",
        "shortage_started_set = set(zip(labels2[\"drug_key\"], labels2[\"year\"]))\n",
        "\n",
        "# Join demand + manufacturer count\n",
        "df = demand.merge(mfg[[\"drug_key\", \"num_manufacturers\"]], on=\"drug_key\", how=\"left\")\n",
        "df[\"num_manufacturers\"] = df[\"num_manufacturers\"].fillna(0).astype(int)\n",
        "\n",
        "# Prior shortage totals by drug\n",
        "hist = labels2.groupby(\"drug_key\")[\"shortages_started\"].sum().to_dict()\n",
        "df[\"prior_shortage_total\"] = df[\"drug_key\"].map(hist).fillna(0).astype(int)\n",
        "\n",
        "# Label: does a shortage start next year?\n",
        "df[\"label_next_year\"] = df.apply(\n",
        "    lambda r: 1 if (r[\"drug_key\"], int(r[\"year\"]) + 1) in shortage_started_set else 0,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Demand growth features\n",
        "df = df.sort_values([\"drug_key\", \"year\"])\n",
        "df[\"claims_prev\"] = df.groupby(\"drug_key\")[\"claims\"].shift(1)\n",
        "df[\"claims_growth_pct\"] = (df[\"claims\"] - df[\"claims_prev\"]) / df[\"claims_prev\"]\n",
        "df[\"claims_growth_pct\"] = df[\"claims_growth_pct\"].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "df.to_csv(\"model_table.csv\", index=False)\n",
        "print(\"Saved model_table.csv (rows):\", len(df), \"| label counts:\", df[\"label_next_year\"].value_counts().to_dict())\n"
      ],
      "metadata": {
        "id": "JY1KYifOeGhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "df = pd.read_csv(\"model_table.csv\")\n",
        "\n",
        "feature_cols = [\"claims\", \"claims_growth_pct\", \"num_manufacturers\", \"prior_shortage_total\"]\n",
        "X = df[feature_cols]\n",
        "y = df[\"label_next_year\"].astype(int)\n",
        "\n",
        "years = sorted(df[\"year\"].unique())\n",
        "if len(years) < 3:\n",
        "    raise RuntimeError(f\"Need at least 3 years for train/val/test split. Years found: {years}\")\n",
        "\n",
        "train_years = years[:-2]\n",
        "val_year = years[-2]\n",
        "test_year = years[-1]\n",
        "\n",
        "train_idx = df[\"year\"].isin(train_years)\n",
        "val_idx = df[\"year\"] == val_year\n",
        "test_idx = df[\"year\"] == test_year\n",
        "\n",
        "X_train, y_train = X[train_idx], y[train_idx]\n",
        "X_val, y_val     = X[val_idx], y[val_idx]\n",
        "X_test, y_test   = X[test_idx], y[test_idx]\n",
        "\n",
        "neg = max((y_train == 0).sum(), 1)\n",
        "pos = max((y_train == 1).sum(), 1)\n",
        "scale_pos_weight = neg / pos\n",
        "\n",
        "train_set = lgb.Dataset(X_train, label=y_train)\n",
        "val_set   = lgb.Dataset(X_val, label=y_val, reference=train_set)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": \"auc\",\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"num_leaves\": 31,\n",
        "    \"max_depth\": 8,\n",
        "    \"min_data_in_leaf\": 20,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.9,\n",
        "    \"bagging_freq\": 1,\n",
        "    \"scale_pos_weight\": scale_pos_weight,\n",
        "    \"verbosity\": -1,\n",
        "    \"seed\": 42,\n",
        "}\n",
        "\n",
        "model = lgb.train(\n",
        "    params,\n",
        "    train_set,\n",
        "    num_boost_round=2000,\n",
        "    valid_sets=[val_set],\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=50),\n",
        "        lgb.log_evaluation(period=100),\n",
        "    ],\n",
        ")\n",
        "\n",
        "pred_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
        "\n",
        "# Metrics only make sense if test has both classes\n",
        "if len(np.unique(y_test)) > 1:\n",
        "    auc = roc_auc_score(y_test, pred_test)\n",
        "    ap = average_precision_score(y_test, pred_test)\n",
        "    print(\"Test AUC:\", round(auc, 4), \"| Test AP:\", round(ap, 4))\n",
        "else:\n",
        "    print(\"Test year has a single class; skipping AUC/AP.\")\n",
        "\n",
        "# Precision@K (how many of the top-K are real positives)\n",
        "test_df = df.loc[test_idx].copy()\n",
        "test_df[\"risk_score\"] = pred_test\n",
        "test_df = test_df.sort_values(\"risk_score\", ascending=False)\n",
        "\n",
        "for k in [10, 20, 50]:\n",
        "    if len(test_df) >= k:\n",
        "        print(f\"Precision@{k}:\", round(test_df.head(k)[\"label_next_year\"].mean(), 3))\n",
        "\n",
        "# Score everything + make a watchlist for latest year\n",
        "df[\"risk_score\"] = model.predict(X, num_iteration=model.best_iteration)\n",
        "\n",
        "latest_year = int(df[\"year\"].max())\n",
        "watch = df[df[\"year\"] == latest_year].sort_values(\"risk_score\", ascending=False).head(50)\n",
        "\n",
        "watch.to_csv(\"watchlist_top50.csv\", index=False)\n",
        "print(\"Saved watchlist_top50.csv (latest year):\", latest_year)\n",
        "\n",
        "imp = pd.DataFrame({\n",
        "    \"feature\": feature_cols,\n",
        "    \"gain\": model.feature_importance(importance_type=\"gain\")\n",
        "}).sort_values(\"gain\", ascending=False)\n",
        "\n",
        "imp.to_csv(\"feature_importance.csv\", index=False)\n",
        "model.save_model(\"dsbios_lgb_model.txt\")\n",
        "\n",
        "print(\"Saved feature_importance.csv and dsbios_lgb_model.txt\")\n"
      ],
      "metadata": {
        "id": "aoBlNNc6eHmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "WATCH = Path(\"watchlist_top50.csv\")\n",
        "if not WATCH.exists():\n",
        "    raise FileNotFoundError(\"watchlist_top50.csv not found. Train cell should create it.\")\n",
        "\n",
        "watch = pd.read_csv(WATCH).sort_values(\"risk_score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "watch[\"risk_rank\"] = np.arange(1, len(watch) + 1)\n",
        "if len(watch) > 1:\n",
        "    watch[\"risk_percentile\"] = (1 - (watch[\"risk_rank\"] - 1) / (len(watch) - 1)) * 100\n",
        "else:\n",
        "    watch[\"risk_percentile\"] = 100.0\n",
        "watch[\"risk_percentile\"] = watch[\"risk_percentile\"].round(1)\n",
        "\n",
        "def tier(p):\n",
        "    if p >= 99: return \"CRITICAL (Top 1%)\"\n",
        "    if p >= 95: return \"HIGH (Top 5%)\"\n",
        "    if p >= 80: return \"ELEVATED (Top 20%)\"\n",
        "    return \"MONITOR\"\n",
        "\n",
        "watch[\"risk_tier\"] = watch[\"risk_percentile\"].apply(tier)\n",
        "\n",
        "def explain(row):\n",
        "    reasons = []\n",
        "    if row.get(\"prior_shortage_total\", 0) >= 2:\n",
        "        reasons.append(\"repeat shortage history\")\n",
        "    if row.get(\"num_manufacturers\", 0) != 0 and row.get(\"num_manufacturers\", 999) <= 2:\n",
        "        reasons.append(\"few manufacturers\")\n",
        "    if row.get(\"claims_growth_pct\", 0) > 0.15:\n",
        "        reasons.append(\"demand rising fast\")\n",
        "    return \", \".join(reasons) if reasons else \"mixed signals (review)\"\n",
        "\n",
        "watch[\"top_reasons\"] = watch.apply(explain, axis=1)\n",
        "\n",
        "top20 = watch.head(20).copy()\n",
        "presentable = top20[[\n",
        "    \"drug_key\", \"year\", \"risk_percentile\", \"risk_tier\",\n",
        "    \"num_manufacturers\", \"claims\", \"claims_growth_pct\",\n",
        "    \"prior_shortage_total\", \"top_reasons\"\n",
        "]].copy()\n",
        "\n",
        "presentable.rename(columns={\n",
        "    \"drug_key\": \"Drug (Canonical)\",\n",
        "    \"year\": \"Prediction Year\",\n",
        "    \"risk_percentile\": \"Risk Percentile\",\n",
        "    \"risk_tier\": \"Risk Tier\",\n",
        "    \"num_manufacturers\": \"# Manufacturers (Orange Book)\",\n",
        "    \"claims\": \"Medicare Part D Claims\",\n",
        "    \"claims_growth_pct\": \"Claims Growth %\",\n",
        "    \"prior_shortage_total\": \"Prior Shortages (OpenFDA)\",\n",
        "    \"top_reasons\": \"Top Reasons\"\n",
        "}, inplace=True)\n",
        "\n",
        "presentable.to_csv(\"top20_submission_table_presentable.csv\", index=False)\n",
        "watch.to_csv(\"watchlist_top50_presentable.csv\", index=False)\n",
        "\n",
        "print(\"Saved top20_submission_table_presentable.csv and watchlist_top50_presentable.csv\")\n",
        "print(presentable.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "0GyPNY0oeJnw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}